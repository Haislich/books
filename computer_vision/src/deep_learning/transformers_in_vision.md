# Transformers in Vision

Transformers were originally developed for natural language processing (NLP) tasks but have since been adapted for vision tasks due to their ability to capture long-range dependencies and model complex relationships in data. While traditional models like CNNs and RNNs have limitations such as vanishing gradients or inability to process sequences in parallel, **Transformers** overcome these challenges using **self-attention** mechanisms.
